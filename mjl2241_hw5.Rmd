---
title: "mjl2241_hw5"
author: "Michelle Lee"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---
This is my solution to HW5. 

```{r setup, include=FALSE}
library(tidyverse)
library (patchwork)
library(readr)
library(broom)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```
### Problem 1.

We start off by downloading the data from The Washing Post, on on homicides in 50 large U.S. cities via Github. After taking a look at the dataset, we also created city_state variable and resolved_status variable to count the total number of homicides and unsolved homicides. 
```{r, error = TRUE download raw github data}
homicide_df =
  tibble(
  read.csv(url("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")))
homicide_df = janitor::clean_names(homicide_df)
skimr::skim(homicide_df)
homicide_df$city_state= 
  paste(homicide_df$city,",", homicide_df$state)

#create resolved variable;
homicide_df = 
  
  homicide_df %>%
  mutate(resolved = case_when(
    disposition == 'Closed without arrest' ~   "unsolved",
    disposition == 'Open/No arrest' ~ "unsolved",
    disposition == 'Closed by arrest' ~ "solved"))   %>%
  select(city_state, resolved)%>%
  filter(city_state != "Tulsa_AL")

homicide_status_df = 
  homicide_df %>%
  group_by(city_state) %>%
  summarize(
    total_hom = n(),
    unsolved_hom = sum(resolved == "unsolved")
  )
```
In this dataset, there is a total of 52,179 unique rows 12 columns. Some of the key variables are disposition, city, state, gender, victims age, victims race, victims name, and the date of the incident. The dataset is mostly complete and do not have missing values in key variables, except for 60 rows in latitude and longitude. 

Using the prop.test on Baltimore, MA
``` {r, error = TRUE baltimore data}
prop.test(
  homicide_status_df %>% filter(city_state == "Baltimore , MD") %>% pull(unsolved_hom), 
  homicide_status_df %>% filter(city_state == "Baltimore , MD") %>% pull(total_hom)) %>% 
  broom::tidy()
```
Applying prop.test on all the cities

``` {r, error = TRUE prop.test on cities}
results_df = 
  homicide_status_df %>% 
  mutate(
    prop_tests = map2(.x = unsolved_hom, .y = total_hom, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low,conf.high)
```
Then we finally created a plot that shows the estimates and CIs for each city.

``` {r, error = TRUE plot for results_df}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

### problem 2

``` {r, error = TRUE read and tidy data}
files = list.files("./data", pattern = ".csv", all.files = FALSE, 
full.names = FALSE)

study_df =
  tibble(
  data.frame(participants = files) %>% 
  mutate(file_contents = map(participants, ~read.csv(file.path("./data", .)))) %>% 
  separate(participants, into = c("arm", "subject_id")) %>% 
  unnest(file_contents) %>% 
  mutate(
    arm = recode(arm, `con` = "control", `exp` = "experiment")
  )) %>%
  select(arm, subject_id,week_1:week_8)%>%
  pivot_longer(
    week_1:week_8,
    names_to = "week_number",
    values_to = "value")
```

```{r, error = TRUE}
study_df = 
  tibble(
    filename = list.files("./data")
  ) %>% 
  mutate(
    path = str_c("./data/", filename),
    data = map(path, read_csv )
  )%>%
  unnest(data)%>%
  separate(filename, into = c("arm","subject_id","csv"), convert = TRUE )%>%
  select(arm, subject_id,week_1:week_8)%>%
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "value")%>%
  mutate(
    
    subject_id = as.character(subject_id)
  )
```
we then made a spaghetti plot

``` {r, error = TRUE spaghetti plot}
study_df %>% 
  ggplot(aes(x = week, y = value, group = subject_id, color = subject_id)) +
  geom_line() + 
  theme_bw () +
  facet_grid(~arm) +
  labs(
    title = "value over time by groups",
    x = "Week",
    y = "Value"
  ) + 
  viridis::scale_color_viridis(discrete = TRUE)
```
Based on the graphs above, participants in the experiment arm had increasing positive values as the week progress, on average. However, participants from the control arm had values that did not significantly increase as the weeks progressed and showed irregular change over time.

### Problem 3
First, we created the sim_regression function
```{r message = FALSE, warning = FALSE}
set.seed(1)

sim_ttest = function(n = 30, mu, sigma = 5) {
  sim_data = tibble (
  x = rnorm(n, mean = mu, sd = sigma)
  )
  
  sim_data %>%
  t.test() %>%
  broom::tidy() 
# %>% select(estimate, p.value)
}
```
We then ran the simulation 5000 times for Î¼={1,2,3,4,5,6} and saved to sim_results dataframe

``` {r sim_results df}
sim_results = tibble(mu = c(0,1,2,3,4,5,6)) %>% 
  mutate(
    output_list = map(.x = mu, ~rerun(5000, sim_ttest(mu = .x))),
    output_df = map(output_list, bind_rows)) %>% 
  select(-output_list) %>% 
  unnest(output_df)

head(sim_results)


```

  